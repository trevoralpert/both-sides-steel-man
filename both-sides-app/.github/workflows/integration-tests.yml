name: Integration Tests

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'backend/src/integration/**'
      - 'backend/prisma/**'
      - 'backend/package*.json'
      - '.github/workflows/integration-tests.yml'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'backend/src/integration/**'
      - 'backend/prisma/**'
      - 'backend/package*.json'
      - '.github/workflows/integration-tests.yml'
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_suite:
        description: 'Test suite to run'
        required: false
        default: 'all'
        type: choice
        options:
          - 'all'
          - 'functional'
          - 'performance'
          - 'security'
          - 'reliability'
          - 'data-integrity'
      environment:
        description: 'Test environment'
        required: false
        default: 'development'
        type: choice
        options:
          - 'development'
          - 'staging'
          - 'production'
      load_test:
        description: 'Run load tests'
        required: false
        default: false
        type: boolean

env:
  NODE_VERSION: '18'
  POSTGRES_VERSION: '15'
  REDIS_VERSION: '7'

jobs:
  setup:
    name: Setup & Validate
    runs-on: ubuntu-latest
    outputs:
      test-matrix: ${{ steps.matrix.outputs.matrix }}
      cache-key: ${{ steps.cache-key.outputs.key }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: 'backend/package-lock.json'

      - name: Generate cache key
        id: cache-key
        run: |
          echo "key=integration-${{ runner.os }}-node${{ env.NODE_VERSION }}-${{ hashFiles('backend/package-lock.json', 'backend/prisma/schema.prisma') }}" >> $GITHUB_OUTPUT

      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: |
            backend/node_modules
            ~/.npm
          key: ${{ steps.cache-key.outputs.key }}
          restore-keys: |
            integration-${{ runner.os }}-node${{ env.NODE_VERSION }}-

      - name: Install dependencies
        working-directory: backend
        run: |
          npm ci --no-audit --no-fund
          npm list

      - name: Generate test matrix
        id: matrix
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            SUITE="${{ github.event.inputs.test_suite }}"
            ENV="${{ github.event.inputs.environment }}"
            LOAD_TEST="${{ github.event.inputs.load_test }}"
          else
            SUITE="all"
            ENV="development"
            LOAD_TEST="false"
          fi
          
          MATRIX=$(cat << EOF
          {
            "include": [
              {
                "name": "Critical Tests",
                "suite": "functional",
                "priority": "critical",
                "timeout": "10m",
                "environment": "$ENV"
              },
              {
                "name": "Security Tests",
                "suite": "security", 
                "priority": "high",
                "timeout": "15m",
                "environment": "$ENV"
              },
              {
                "name": "Performance Tests",
                "suite": "performance",
                "priority": "medium",
                "timeout": "20m",
                "environment": "$ENV",
                "run_if": "performance"
              },
              {
                "name": "Data Integrity Tests",
                "suite": "data-integrity",
                "priority": "high",
                "timeout": "15m",
                "environment": "$ENV"
              }
            ]
          }
          EOF
          )
          
          if [ "$SUITE" != "all" ]; then
            MATRIX=$(echo $MATRIX | jq ".include |= map(select(.suite == \"$SUITE\"))")
          fi
          
          if [ "$LOAD_TEST" = "true" ]; then
            MATRIX=$(echo $MATRIX | jq '.include += [{"name": "Load Tests", "suite": "load-test", "priority": "medium", "timeout": "30m", "environment": "'$ENV'"}]')
          fi
          
          echo "matrix=$(echo $MATRIX | jq -c .)" >> $GITHUB_OUTPUT

  services:
    name: Start Services
    runs-on: ubuntu-latest
    needs: setup
    
    services:
      postgres:
        image: postgres:${{ env.POSTGRES_VERSION }}
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_USER: postgres
          POSTGRES_DB: bothsides_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:${{ env.REDIS_VERSION }}
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Verify services
        run: |
          echo "Postgres status: $(pg_isready -h localhost -p 5432)"
          echo "Redis status: $(redis-cli -h localhost -p 6379 ping)"

  integration-tests:
    name: ${{ matrix.name }}
    runs-on: ubuntu-latest
    needs: [setup, services]
    timeout-minutes: 30
    
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.setup.outputs.test-matrix) }}

    env:
      DATABASE_URL: "postgresql://postgres:postgres@localhost:5432/bothsides_test"
      REDIS_URL: "redis://localhost:6379"
      NODE_ENV: "test"
      JWT_SECRET: "test-secret-key"
      INTEGRATION_TEST_MODE: "true"

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: 'backend/package-lock.json'

      - name: Restore dependencies
        uses: actions/cache@v3
        with:
          path: |
            backend/node_modules
            ~/.npm
          key: ${{ needs.setup.outputs.cache-key }}
          fail-on-cache-miss: true

      - name: Setup database
        working-directory: backend
        run: |
          npm run db:generate
          npm run db:push
          npm run db:seed:test

      - name: Run integration tests
        working-directory: backend
        timeout-minutes: ${{ fromJson(matrix.timeout) }}
        run: |
          if [ "${{ matrix.suite }}" = "load-test" ]; then
            npm run test:integration -- --load-test --environment ${{ matrix.environment }}
          else
            npm run test:integration -- --suite ${{ matrix.suite }} --environment ${{ matrix.environment }}
          fi

      - name: Generate test report
        if: always()
        working-directory: backend
        run: |
          npm run test:integration:report -- --suite ${{ matrix.suite }} --format html

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.suite }}
          path: |
            backend/test-results/
            backend/coverage/
          retention-days: 30

      - name: Upload performance baseline
        if: matrix.suite == 'performance' && github.ref == 'refs/heads/main'
        uses: actions/upload-artifact@v4
        with:
          name: performance-baseline
          path: backend/test-results/performance-baseline.json

  quality-gates:
    name: Quality Gates
    runs-on: ubuntu-latest
    needs: [setup, integration-tests]
    if: always()

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Download test results
        uses: actions/download-artifact@v4
        with:
          path: test-results/
          pattern: test-results-*
          merge-multiple: true

      - name: Analyze results
        run: |
          # Calculate overall pass rate
          TOTAL_TESTS=$(find test-results -name "*.json" -exec jq -r '.summary.total // 0' {} + | awk '{sum+=$1} END {print sum}')
          PASSED_TESTS=$(find test-results -name "*.json" -exec jq -r '.summary.passed // 0' {} + | awk '{sum+=$1} END {print sum}')
          
          if [ $TOTAL_TESTS -gt 0 ]; then
            PASS_RATE=$(echo "scale=2; $PASSED_TESTS * 100 / $TOTAL_TESTS" | bc)
          else
            PASS_RATE=0
          fi
          
          echo "TOTAL_TESTS=$TOTAL_TESTS" >> $GITHUB_ENV
          echo "PASSED_TESTS=$PASSED_TESTS" >> $GITHUB_ENV
          echo "PASS_RATE=$PASS_RATE" >> $GITHUB_ENV
          
          echo "📊 Test Summary:"
          echo "Total Tests: $TOTAL_TESTS"
          echo "Passed Tests: $PASSED_TESTS"
          echo "Pass Rate: ${PASS_RATE}%"

      - name: Check quality gates
        run: |
          MIN_PASS_RATE=90
          CRITICAL_FAILURES=$(find test-results -name "*.json" -exec jq -r 'select(.regressions // [] | map(select(.severity == "critical")) | length > 0) | .summary.failed // 0' {} + | awk '{sum+=$1} END {print sum+0}')
          
          echo "🚦 Quality Gate Results:"
          echo "Pass Rate: ${PASS_RATE}% (minimum: ${MIN_PASS_RATE}%)"
          echo "Critical Failures: $CRITICAL_FAILURES (maximum: 0)"
          
          if (( $(echo "$PASS_RATE < $MIN_PASS_RATE" | bc -l) )); then
            echo "❌ Quality gate failed: Pass rate ${PASS_RATE}% is below minimum ${MIN_PASS_RATE}%"
            exit 1
          fi
          
          if [ $CRITICAL_FAILURES -gt 0 ]; then
            echo "❌ Quality gate failed: $CRITICAL_FAILURES critical test failures detected"
            exit 1
          fi
          
          echo "✅ All quality gates passed!"

      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const passRate = process.env.PASS_RATE;
            const totalTests = process.env.TOTAL_TESTS;
            const passedTests = process.env.PASSED_TESTS;
            
            const body = `## 🧪 Integration Test Results
            
            | Metric | Value |
            |--------|-------|
            | **Total Tests** | ${totalTests} |
            | **Passed** | ${passedTests} |
            | **Pass Rate** | ${passRate}% |
            | **Quality Gates** | ✅ Passed |
            
            ### Test Coverage
            - ✅ Functional Tests
            - ✅ Security Tests  
            - ✅ Data Integrity Tests
            - ✅ Performance Tests (if triggered)
            
            <details>
            <summary>View detailed results</summary>
            
            Test artifacts are available in the workflow run.
            </details>`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });

  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [quality-gates]
    if: github.ref == 'refs/heads/develop' && needs.quality-gates.result == 'success'
    environment: staging

    steps:
      - name: Deploy to staging
        run: |
          echo "🚀 Deploying to staging environment..."
          # Add actual deployment steps here

      - name: Run smoke tests
        run: |
          echo "🔍 Running staging smoke tests..."
          # Add smoke test execution here

  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [quality-gates]
    if: github.ref == 'refs/heads/main' && needs.quality-gates.result == 'success'
    environment: production

    steps:
      - name: Deploy to production
        run: |
          echo "🚀 Deploying to production environment..."
          # Add actual deployment steps here

      - name: Run production validation
        run: |
          echo "✅ Running production validation tests..."
          # Add production validation here

  cleanup:
    name: Cleanup
    runs-on: ubuntu-latest
    needs: [integration-tests, quality-gates]
    if: always()

    steps:
      - name: Cleanup test resources
        run: |
          echo "🧹 Cleaning up test resources..."
          # Add cleanup steps here

  notify:
    name: Notifications
    runs-on: ubuntu-latest
    needs: [quality-gates]
    if: always()

    steps:
      - name: Notify on failure
        if: needs.quality-gates.result == 'failure'
        run: |
          echo "📧 Sending failure notifications..."
          # Add notification logic here (Slack, email, etc.)

      - name: Notify on success
        if: needs.quality-gates.result == 'success' && github.ref == 'refs/heads/main'
        run: |
          echo "📧 Sending success notifications..."
          # Add success notification logic here
